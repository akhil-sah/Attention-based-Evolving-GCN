{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6yCGmvaoFJo"
      },
      "source": [
        "# EvolveGAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4SGfIxboI5P"
      },
      "source": [
        "### Dependency Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4roYRFolSZg",
        "outputId": "d032ee10-7f53-421b-b66d-15d840ddf546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 12.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 12.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 9.4 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/benedekrozemberczki/pytorch_geometric_temporal.git\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylaMfYigtD5U"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y9J5VfIHwKh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn18nJLXJAdW"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0kyTnAalK2n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.loader import DataLoader \n",
        "import torch_geometric.transforms as T\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tCe8WLXeeP2",
        "outputId": "bcbfbba6-7fe2-429c-fd8a-53c399777360"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://snap.stanford.edu/data/soc-sign-bitcoinotc.csv.gz\n",
            "Extracting data/raw/soc-sign-bitcoinotc.csv.gz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: BitcoinOTC(50):\n",
            "======================\n",
            "Number of graphs: 50\n",
            "Number of features: 0\n",
            "Number of classes: 0\n",
            "Is Undirected:  False\n",
            "Data(edge_index=[2, 41], edge_attr=[41], num_nodes=6005)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Bitcoin OTC\n",
        "import torch\n",
        "from torch_geometric.datasets import BitcoinOTC\n",
        "from torch_geometric.loader import DataLoader \n",
        "import torch_geometric.transforms as T\n",
        "import random\n",
        "\n",
        "dataset = BitcoinOTC(root = './data')\n",
        "dataset = dataset[:50]\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "print(f'Is Undirected:  {dataset[0].is_undirected()}')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train_test split\n",
        "#we can also use temporal_signal_split\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size = 0.2, shuffle = False)\n",
        "print(dataset[0])\n",
        "\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5val-ZngItp4",
        "outputId": "96114bb2-1512-4db2-ae26-2eed4288fc48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXH8n0xMtCx9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exdw_-SnI52y"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE3fy0jAy3Js"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNA8Vjgoy3SG"
      },
      "outputs": [],
      "source": [
        "def normalizeAdjacency(W):\n",
        "    # Check that the matrix is square\n",
        "    assert W.shape[0] == W.shape[1]\n",
        "    # Compute the degree vector\n",
        "    d = torch.sum(W, axis = 1)\n",
        "    # Invert the square root of the degree\n",
        "    d = 1/torch.sqrt(d)\n",
        "    # And build the square root inverse degree matrix\n",
        "    D = torch.diag(d)\n",
        "    # Return the Normalized Adjacency\n",
        "    return D @ W @ D \n",
        "\n",
        "#Snapshot to adjacency matrix\n",
        "def snap_to_adjmat(snapshot):\n",
        "    x = torch.FloatTensor(torch.zeros(snapshot.num_nodes, snapshot.num_nodes))\n",
        "    for j in range(snapshot.edge_index.size()[1]):\n",
        "        v1 = snapshot.edge_index[:,j][0].item()\n",
        "        v2 = snapshot.edge_index[:,j][1].item()\n",
        "        x[v1][v2] = 1.0\n",
        "    for i in range(snapshot.num_nodes):\n",
        "        x[i][i] = 1.0\n",
        "\n",
        "    #symetric normalisation(High time complexity)\n",
        "    #x = normalizeAdjacency(x);\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzrrXTLly3XI",
        "outputId": "8062a46c-1568-4c22-82f6-299977da4f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.FloatTensor\n",
            "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "temp = snap_to_adjmat(dataset[0])\n",
        "print(temp.type())\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MV0sSZqzUZr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYHMvP63zAyy"
      },
      "outputs": [],
      "source": [
        "#Similarity index\n",
        "def similarity(vec1, vec2):\n",
        "    return torch.dot(vec1, vec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbgwKwd9zMwW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2Id2RMDcE4k"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import GRU\n",
        "from torch_geometric.typing import Adj, OptTensor\n",
        "from torch_sparse import SparseTensor\n",
        "from torch_geometric.nn.inits import glorot\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "\n",
        "class GCNConv_Fixed_W(MessagePassing):\n",
        "    _cached_edge_index: Optional[Tuple[Tensor, Tensor]]\n",
        "    _cached_adj_t: Optional[SparseTensor]\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int,\n",
        "                 improved: bool = False, cached: bool = False,\n",
        "                 add_self_loops: bool = True, normalize: bool = True,\n",
        "                **kwargs):\n",
        "\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super(GCNConv_Fixed_W, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.improved = improved\n",
        "        self.cached = cached\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self._cached_edge_index = None\n",
        "        self._cached_adj_t = None\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self._cached_edge_index = None\n",
        "        self._cached_adj_t = None\n",
        "\n",
        "\n",
        "    def forward(self, W: torch.FloatTensor, x: Tensor, edge_index: Adj,\n",
        "                edge_weight: OptTensor = None) -> Tensor:\n",
        "\n",
        "        if self.normalize:\n",
        "            cache = self._cached_edge_index\n",
        "            if cache is None:\n",
        "                edge_index, edge_weight = gcn_norm(  # yapf: disable\n",
        "                    edge_index, edge_weight, x.size(self.node_dim),\n",
        "                    self.improved, self.add_self_loops, dtype = float)\n",
        "\n",
        "        x = torch.matmul(x, W)\n",
        "\n",
        "        # propagate_type: (x: Tensor, edge_weight: OptTensor)\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n",
        "                             size=None)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "class attention(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(attention, self).__init__()\n",
        "\n",
        "  def forward(self, X: Tensor, edge_index: Adj) -> Tensor:\n",
        "    embed_prod = torch.zeros(X.shape[0], X.shape[0])\n",
        "    for i in range(X.shape[0]):\n",
        "      embed_prod[i] = torch.exp(torch.sum(torch.mul(X[i], X), axis = 1))\n",
        "    \n",
        "    alpha = torch.zeros(X.shape[0])\n",
        "    edges = edge_index.T\n",
        "    for edge in edges:\n",
        "      alpha[edge[0]] += embed_prod[edge[0]][edge[1]]\n",
        "    \n",
        "    for i in range(X.shape[0]):\n",
        "      alpha[i] += embed_prod[i][i]\n",
        "    \n",
        "    for i in range(X.shape[0]):\n",
        "      embed_prod[i] /= alpha[i]\n",
        "#    Y = X.detach()\n",
        "    Y = torch.zeros(X.shape[0], X.shape[1]).to(device)\n",
        "    for i in range(X.shape[0]):\n",
        "      Y[i] = torch.mul(embed_prod[i][i], X[i])\n",
        "    \n",
        "    for edge in edges:\n",
        "      Y[edge[0]] += torch.mul(embed_prod[edge[0]][edge[1]], X[edge[1]])\n",
        "    return X\n",
        "    \n",
        "class EvolveGCNO_(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        improved: bool = False,\n",
        "        cached: bool = False,\n",
        "        normalize: bool = True,\n",
        "        add_self_loops: bool = True,\n",
        "    ):\n",
        "        super(EvolveGCNO_, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.improved = improved\n",
        "        self.cached = cached\n",
        "        self.normalize = normalize\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.weight = None\n",
        "        self.initial_weight = torch.nn.Parameter(torch.Tensor(in_channels, in_channels))\n",
        "        self._create_layers()\n",
        "        self.reset_parameters()\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        glorot(self.initial_weight)\n",
        "\n",
        "\n",
        "    def _create_layers(self):\n",
        "\n",
        "        self.recurrent_layer = GRU(\n",
        "            input_size=self.in_channels, hidden_size=self.in_channels, num_layers=1\n",
        "        )\n",
        "        for param in self.recurrent_layer.parameters():\n",
        "            param.requires_grad = True\n",
        "            param.retain_grad()\n",
        "\n",
        "        self.conv_layer = GCNConv_Fixed_W(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.in_channels,\n",
        "            improved=self.improved,\n",
        "            cached=self.cached,\n",
        "            normalize=self.normalize,\n",
        "            add_self_loops=self.add_self_loops\n",
        "        )\n",
        "\n",
        "        self.attention_layer = attention()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        X: torch.FloatTensor,\n",
        "        edge_index: torch.LongTensor,\n",
        "        edge_weight: torch.FloatTensor = None,\n",
        "    ) -> torch.FloatTensor:\n",
        "\n",
        "        if self.weight is None:\n",
        "            self.weight = self.initial_weight.data\n",
        "        W = self.weight[None, :, :]\n",
        "        _, W = self.recurrent_layer(W, W)\n",
        "        X = self.conv_layer(W.squeeze(dim=0), X, edge_index, edge_weight)\n",
        "        X = self.attention_layer(X, edge_index)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NZiYu5mI5T8"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwauB6VPYhTp"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVyzI-cO4xud"
      },
      "outputs": [],
      "source": [
        "num_nodes = dataset[0].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EABedFRlOPM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric_temporal.nn.recurrent import EvolveGCNO\n",
        "from torch_geometric.nn import GATConv\n",
        "import torch.nn as nn\n",
        "\n",
        "class EvolveGAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, emb_dim):\n",
        "        super(EvolveGAT, self).__init__()\n",
        "        self.linear = torch.nn.Linear(num_nodes, emb_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.recurrent = EvolveGCNO_(in_channels, add_self_loops=False, normalize=False)\n",
        "        \n",
        "    #forward propogation\n",
        "    def encode(self, x, edge_index, edge_weight):\n",
        "        h = self.linear(x)\n",
        "        h = F.relu(h)\n",
        "        h = self.recurrent(h, edge_index, edge_weight)\n",
        "        return h\n",
        "\n",
        "    #for edge classification (per edge)\n",
        "    def decode(self, z, pos_edge_index, neg_edge_index): # only pos and neg edges\n",
        "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
        "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
        "        return logits\n",
        "\n",
        "    #for all edge \n",
        "    def decode_all(self, z): \n",
        "        prob_adj = z @ z.t() # get adj NxN\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t() # get predicted edge_list \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUBMmqEvPAJP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Xw4iWvvjJk",
        "outputId": "b24bb119-e857-4b69-8bb6-0df861bb84c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 41], edge_attr=[41], num_nodes=6005)\n",
            "tensor([ 4,  2,  1,  7,  8,  8,  1,  5,  5,  5,  8,  8,  9,  7,  5,  1,  8,  7,\n",
            "         8,  1, 10,  7,  7,  1,  1,  3,  3,  1,  4,  2,  5,  5,  1,  2,  2,  2,\n",
            "         2,  2,  1,  2,  1])\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0])\n",
        "temp = train_dataset[0].edge_attr\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGCCxhKFAnKv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SICVajsIY9og"
      },
      "source": [
        "### Data Management For Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--rTJJ6iMrXz"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch_geometric.utils import negative_sampling\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMAgCXy5StxY"
      },
      "outputs": [],
      "source": [
        "def get_link_labels(pos_edge_index, neg_edge_index):\n",
        "    # returns a tensor:\n",
        "    # [1,1,1,1,...,0,0,0,0,0,..] with the number of ones is equel to the lenght of pos_edge_index\n",
        "    # and the number of zeros is equal to the length of neg_edge_index\n",
        "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
        "    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
        "    link_labels[:pos_edge_index.size(1)] = 1.\n",
        "    return link_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOUDPt2_Wyeq"
      },
      "outputs": [],
      "source": [
        "neg_edge_index = negative_sampling(\n",
        "    edge_index = dataset[0].edge_index, #positive edges\n",
        "    num_nodes = dataset[0].num_nodes, # number of nodes\n",
        "    num_neg_samples = dataset[0].edge_index.size(1)\n",
        ") \n",
        "pos_edge_index = dataset[0].edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMUyaA4kW5OR",
        "outputId": "fccc919d-afa1-48e1-de68-8b225f97179f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 41])\n",
            "torch.Size([2, 41])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#Check fns.\n",
        "print(pos_edge_index.size())\n",
        "print(neg_edge_index.size())\n",
        "E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
        "link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
        "link_labels[:pos_edge_index.size(1)] = 1.\n",
        "print(link_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVcIkSJRW5BU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps5eLpIxXP5-"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptYB_JtxWyLQ"
      },
      "source": [
        "### Model Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgPTQiaXYU1N"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "emb_dim = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhX-A8xYnLre",
        "outputId": "b97f761e-fc3a-4e86-d0e4-2dfd197c10ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▎         | 1/40 [01:40<1:05:30, 100.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 0 Cost: 0.4413000546395779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 2/40 [03:21<1:03:37, 100.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 1 Cost: 0.4511335365474224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 3/40 [05:00<1:01:42, 100.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 2 Cost: 0.4106707192957401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 4/40 [06:40<1:00:04, 100.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 3 Cost: 0.3968939408659935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 5/40 [08:20<58:22, 100.08s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 4 Cost: 0.39792146161198616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 6/40 [10:01<56:51, 100.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 5 Cost: 0.389914071559906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 7/40 [11:41<55:06, 100.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 6 Cost: 0.3918401598930359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 8/40 [13:22<53:35, 100.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 7 Cost: 0.38630159199237823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▎       | 9/40 [15:02<51:45, 100.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 8 Cost: 0.3827245146036148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 10/40 [16:42<50:04, 100.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 9 Cost: 0.38024971038103106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 11/40 [18:22<48:20, 100.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 10 Cost: 0.37987208291888236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 12/40 [20:01<46:36, 99.88s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 11 Cost: 0.38790847882628443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▎      | 13/40 [21:43<45:10, 100.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 12 Cost: 0.38100242912769317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 14/40 [23:24<43:39, 100.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 13 Cost: 0.3759559251368046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 15/40 [25:04<41:53, 100.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 14 Cost: 0.37406411617994306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 16/40 [26:44<40:06, 100.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 15 Cost: 0.37233448699116706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▎     | 17/40 [28:23<38:20, 100.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 16 Cost: 0.3686654657125473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 18/40 [30:03<36:38, 99.95s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 17 Cost: 0.36863752976059916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 19/40 [31:43<34:56, 99.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 18 Cost: 0.36727034375071527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 20/40 [33:22<33:15, 99.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 19 Cost: 0.3661870755255222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▎    | 21/40 [35:02<31:36, 99.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 20 Cost: 0.3660787224769592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 22/40 [36:42<29:57, 99.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 21 Cost: 0.36710974499583243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▊    | 23/40 [38:22<28:18, 99.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 22 Cost: 0.3672539196908474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 24/40 [40:02<26:38, 99.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 23 Cost: 0.3702981732785702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 25/40 [41:41<24:55, 99.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 24 Cost: 0.3700785845518112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 26/40 [43:21<23:14, 99.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 25 Cost: 0.3670659430325031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 27/40 [45:01<21:37, 99.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 26 Cost: 0.3645859181880951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 28/40 [46:41<19:58, 99.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 27 Cost: 0.3652326077222824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▎  | 29/40 [48:21<18:17, 99.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 28 Cost: 0.3665553942322731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 30/40 [50:01<16:38, 99.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 29 Cost: 0.3710139572620392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 31/40 [51:40<14:56, 99.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 30 Cost: 0.36931305155158045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 32/40 [53:20<13:17, 99.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 31 Cost: 0.37201839238405227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▎ | 33/40 [55:00<11:39, 99.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 32 Cost: 0.3752685755491257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 34/40 [56:39<09:57, 99.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 33 Cost: 0.3708330810070038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 35/40 [58:18<08:17, 99.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 34 Cost: 0.36770572438836097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 36/40 [59:58<06:38, 99.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 35 Cost: 0.371434173732996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▎| 37/40 [1:01:37<04:58, 99.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 36 Cost: 0.3725754089653492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 38/40 [1:03:16<03:18, 99.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 37 Cost: 0.36906213983893393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 39/40 [1:04:55<01:39, 99.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 38 Cost: 0.3705383911728859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [1:06:33<00:00, 99.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 39 Cost: 0.36832466796040536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.36832466796040536"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "model = EvolveGAT(in_channels = emb_dim, emb_dim = emb_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "def train():\n",
        "    for epoch in tqdm(range(40)):\n",
        "        cost = 0\n",
        "        for time, snapshot in enumerate(train_dataset):\n",
        "            adj_mat = snap_to_adjmat(snapshot).to(device)\n",
        "            next_snap = dataset[time]\n",
        "\n",
        "            neg_edge_index = negative_sampling(\n",
        "                edge_index = next_snap.edge_index, #positive edges\n",
        "                num_nodes = next_snap.num_nodes, # number of nodes\n",
        "                num_neg_samples = next_snap.edge_index.size(1)\n",
        "                ) # number of neg_sample equal to number of pos_edges\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_hat = model.encode(adj_mat, snapshot.edge_index.to(device), edge_weight = None)\n",
        "            link_logits = model.decode(y_hat, next_snap.edge_index, neg_edge_index) # decode\n",
        "            link_labels = get_link_labels(next_snap.edge_index, neg_edge_index)\n",
        "            \n",
        "            loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
        "            loss.backward()\n",
        "            cost += loss.item()\n",
        "            optimizer.step()\n",
        "        cost /= len(train_dataset) \n",
        "        print(f'Time: {epoch}', f'Cost: {cost}')\n",
        "    return cost\n",
        "#torch.autograd.set_detect_anomaly(True)\n",
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-EpQwzwWWOm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B7j1xxQZy5W"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM7ADuo4ZymC"
      },
      "source": [
        "### Model Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA7Owi4SnbId"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7D9npzHqusQ",
        "outputId": "6c935aab-b0b5-4bde-e6a7-0abf9b8ddc09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EvolveGAT(\n",
              "  (linear): Linear(in_features=6005, out_features=30, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (recurrent): EvolveGCNO_(\n",
              "    (recurrent_layer): GRU(30, 30)\n",
              "    (conv_layer): GCNConv_Fixed_W(30, 30)\n",
              "    (attention_layer): attention()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hka4jD9JnFT4",
        "outputId": "c390313e-ef8c-4675-8f9b-04a4b49e5d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC Score\n",
            "Time: 0 -> AUC: 0.5627602617489589\n",
            "Time: 1 -> AUC: 0.6180555555555556\n",
            "Time: 2 -> AUC: 0.6039603960396039\n",
            "Time: 3 -> AUC: 0.5948228634039444\n",
            "Time: 4 -> AUC: 0.5705174927113703\n",
            "Time: 5 -> AUC: 0.5533479321333831\n",
            "Time: 6 -> AUC: 0.5600595151691101\n",
            "Time: 7 -> AUC: 0.542219257448605\n",
            "Time: 8 -> AUC: 0.5349086969093261\n"
          ]
        }
      ],
      "source": [
        "print('AUC Score')\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    perf = []\n",
        "    for time, snapshot in enumerate(test_dataset[:-1]):\n",
        "        adj_mat = snap_to_adjmat(snapshot).to(device)\n",
        "        next_snap = dataset[time]\n",
        "\n",
        "        pos_edge_index = next_snap.edge_index\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index = next_snap.edge_index, #positive edges\n",
        "            num_nodes = next_snap.num_nodes, # number of nodes\n",
        "            num_neg_samples = next_snap.edge_index.size(1)\n",
        "            ) # number of neg_sample equal to number of pos_edges\n",
        "\n",
        "\n",
        "        y_hat = model.encode(adj_mat, snapshot.edge_index.to(device), edge_weight = None)\n",
        "        link_logits = model.decode(y_hat, next_snap.edge_index, neg_edge_index) # decode\n",
        "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
        "        link_labels = get_link_labels(next_snap.edge_index, neg_edge_index)\n",
        "        \n",
        "        auc = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
        "        print(f'Time: {time} -> AUC: {auc}')\n",
        "        perf.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score \n",
        "    return perf\n",
        "perf = test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K53sjs10nPHk"
      },
      "outputs": [],
      "source": [
        "print('Precision Score')\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    perf = []\n",
        "    for time, snapshot in enumerate(test_dataset[:-1]):\n",
        "        adj_mat = snap_to_adjmat(snapshot).to(device)\n",
        "        next_snap = dataset[time]\n",
        "\n",
        "        pos_edge_index = next_snap.edge_index\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index = next_snap.edge_index, #positive edges\n",
        "            num_nodes = next_snap.num_nodes, # number of nodes\n",
        "            num_neg_samples = next_snap.edge_index.size(1)\n",
        "            ) # number of neg_sample equal to number of pos_edges\n",
        "\n",
        "\n",
        "        y_hat = model.encode(adj_mat, snapshot.edge_index.to(device), edge_weight = None)\n",
        "        link_logits = model.decode(y_hat, next_snap.edge_index, neg_edge_index) # decode\n",
        "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
        "        link_labels = get_link_labels(next_snap.edge_index, neg_edge_index)\n",
        "        \n",
        "        auc = precision_score(link_labels.cpu(), link_probs.cpu())\n",
        "        print(f'Time: {time} -> AUC: {auc}')\n",
        "        perf.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score \n",
        "    return perf\n",
        "perf = test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhWXU1hKphZp"
      },
      "outputs": [],
      "source": [
        "print('Recall Score')\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    perf = []\n",
        "    for time, snapshot in enumerate(test_dataset[:-1]):\n",
        "        adj_mat = snap_to_adjmat(snapshot).to(device)\n",
        "        next_snap = dataset[time]\n",
        "\n",
        "        pos_edge_index = next_snap.edge_index\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index = next_snap.edge_index, #positive edges\n",
        "            num_nodes = next_snap.num_nodes, # number of nodes\n",
        "            num_neg_samples = next_snap.edge_index.size(1)\n",
        "            ) # number of neg_sample equal to number of pos_edges\n",
        "\n",
        "\n",
        "        y_hat = model.encode(adj_mat, snapshot.edge_index.to(device), edge_weight = None)\n",
        "        link_logits = model.decode(y_hat, next_snap.edge_index, neg_edge_index) # decode\n",
        "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
        "        link_labels = get_link_labels(next_snap.edge_index, neg_edge_index)\n",
        "        \n",
        "        auc = recall_score(link_labels.cpu(), link_probs.cpu())\n",
        "        print(f'Time: {time} -> AUC: {auc}')\n",
        "        perf.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score \n",
        "    return perf\n",
        "perf = test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BygfXmQQpzCb"
      },
      "outputs": [],
      "source": [
        "print('F1 Score')\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    perf = []\n",
        "    for time, snapshot in enumerate(test_dataset[:-1]):\n",
        "        adj_mat = snap_to_adjmat(snapshot).to(device)\n",
        "        next_snap = dataset[time]\n",
        "\n",
        "        pos_edge_index = next_snap.edge_index\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index = next_snap.edge_index, #positive edges\n",
        "            num_nodes = next_snap.num_nodes, # number of nodes\n",
        "            num_neg_samples = next_snap.edge_index.size(1)\n",
        "            ) # number of neg_sample equal to number of pos_edges\n",
        "\n",
        "\n",
        "        y_hat = model.encode(adj_mat, snapshot.edge_index.to(device), edge_weight = None)\n",
        "        link_logits = model.decode(y_hat, next_snap.edge_index, neg_edge_index) # decode\n",
        "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
        "        link_labels = get_link_labels(next_snap.edge_index, neg_edge_index)\n",
        "        \n",
        "        auc = recall_score(link_labels.cpu(), link_probs.cpu())\n",
        "        print(f'Time: {time} -> AUC: {auc}')\n",
        "        perf.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score \n",
        "    return perf\n",
        "perf = test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Final EvolveGAT2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}